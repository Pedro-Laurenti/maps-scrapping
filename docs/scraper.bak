#!/usr/bin/env python3
import json
import sys
import asyncio
import re
from typing import Dict, List, Optional, Any
from playwright.async_api import async_playwright, Page, TimeoutError

async def extract_business_details(page: Page, business_element, max_details: bool = True) -> Dict[str, Any]:
    """
    Extrai detalhes de um elemento de negócio no Google Maps
    
    Args:
        page: Objeto Page do Playwright
        business_element: Elemento HTML que representa o negócio
        max_details: Se True, clica no elemento para extrair mais detalhes
        
    Returns:
        Dicionário com os detalhes do negócio
    """
    business_data = {
        "name": None,
        "address": None,
        "phone": None,
        "website": None,
        "rating": None,
        "reviews_count": None,
        "categories": None,
        "hours": None,
        "coordinates": None
    }
    
    # Extrair nome do estabelecimento (disponível no atributo aria-label ou como texto)
    try:
        name = await business_element.get_attribute('aria-label')
        if not name:
            name_element = await business_element.query_selector('div[role="heading"]')
            if name_element:
                name = await name_element.inner_text()
                
        if not name:
            # Tentativa com JS para extrair nome de várias fontes possíveis
            name = await business_element.evaluate("""
                (el) => {
                    if (el.hasAttribute('aria-label')) return el.getAttribute('aria-label');
                    const heading = el.querySelector('[role="heading"], h1, h2, h3, .fontHeadlineLarge');
                    return heading ? heading.innerText : null;
                }
            """)
        
        if name:
            business_data["name"] = name.strip()
    except Exception as e:
        print(f"Erro ao extrair nome: {str(e)}", file=sys.stderr)
    
    # Se não temos detalhes suficientes ou max_details é True, clicamos no item para ver mais informações
    if max_details and business_data.get("name"):
        original_url = None  # Inicializar fora do try para evitar referências antes da atribuição
        
        try:
            # Salvar URL atual para poder voltar
            original_url = await page.url()
            
            # Clicar no elemento para abrir detalhes
            await business_element.click()
            
            # Aguardar o carregamento dos detalhes - mais abrangente e com timeout maior
            try:
                # Conjunto expandido de seletores para verificar se o painel de detalhes está aberto
                detail_selectors = [
                    'div.m6QErb[role="region"]',  # Container principal de detalhes
                    'h1.DUwDvf',                  # Header name
                    'div[role="dialog"]',         # Dialog de detalhes
                    'div.x3AX1-LfntMc-header-title-title', # Novo header
                    'button[aria-label*="back"]',  # Botão voltar
                    'button[jsaction*="back"]',     # Botão voltar alternativo
                    'div.RcCsl',                   # Container de detalhes
                ]
                
                # Dar mais tempo para o carregamento dos detalhes
                selector_found = False
                for selector in detail_selectors:
                    try:
                        await page.wait_for_selector(selector, timeout=3000)
                        print(f"Encontrado seletor de detalhes: {selector}", file=sys.stderr)
                        selector_found = True
                        break
                    except Exception:  # Usar Exception genérica em vez de TimeoutError específica
                        continue
                
                if not selector_found:
                    print("Nenhum seletor de detalhes encontrado, tentando continuar...", file=sys.stderr)
                
                # Pequena pausa para garantir que os dados estejam carregados
                await asyncio.sleep(2)
                
                # Extrair os detalhes adicionais via JavaScript
                details_data = await page.evaluate('''
                () => {
                    // Função para extrair texto de um elemento se existir
                    const getText = (selector) => {
                        const el = document.querySelector(selector);
                        return el ? el.innerText.trim() : null;
                    };
                    
                    // Função para extrair atributo de um elemento se existir
                    const getAttr = (selector, attr) => {
                        const el = document.querySelector(selector);
                        return el ? el.getAttribute(attr) : null;
                    };
                    
                    // Obter nome (múltiplas opções de seletores)
                    const name = getText('h1.DUwDvf') || 
                                getText('h1.fontHeadlineLarge') || 
                                getText('h1') ||
                                getText('div[role="heading"]');
                    
                    // Obter endereço
                    const address = getText('button[data-item-id="address"]') || 
                                   getText('button[jsaction*="address"]') ||
                                   getText('div[data-tooltip="Copiar endereço"]') ||
                                   getText('button[aria-label*="Address"]');
                    
                    // Obter telefone                    
                    const phone = getText('button[data-item-id*="phone"]') || 
                                getText('button[jsaction*="phone"]') ||
                                getText('button[aria-label*="phone"]');
                    
                    // Obter site
                    const website = getAttr('a[data-item-id*="website"]', 'href') || 
                                   getAttr('a[jsaction*="website"]', 'href') ||
                                   getAttr('a[aria-label*="website"]', 'href');
                    
                    // Obter classificação
                    let rating = null;
                    let reviewsCount = null;
                    
                    // Várias tentativas para ratings
                    const ratingText = getText('span.F7nice') || 
                                      getText('div.TLYLSe') ||
                                      getText('span.fontBodyMedium span span');
                                        if (ratingText) {
                        // Capturar o valor da classificação (número com um decimal)
                        const ratingMatch = ratingText.match(/([0-9]+\\.[0-9])/);
                        if (ratingMatch) rating = parseFloat(ratingMatch[1]);
                        
                        // Capturar o número de reviews
                        const reviewsMatch = ratingText.match(/([0-9,.]+)/g);
                        if (reviewsMatch && reviewsMatch.length > 1) {
                            reviewsCount = reviewsMatch[1].replace(/[^0-9]/g, '');
                        }
                    }
                    
                    // Obter categorias
                    const categories = getText('button[jsaction*="category"]') ||
                                      getText('button[aria-label*="category"]');
                    
                    // Obter horários
                    const hours = getText('div[data-item-id*="hours"]') ||
                                 getText('div[jsaction*="hours"]') ||
                                 getText('div[aria-label*="hour"]');
                                 
                    return {
                        name,
                        address,
                        phone,
                        website,
                        rating,
                        reviews_count: reviewsCount,
                        categories,
                        hours
                    };
                }
                ''')
                
                # Incorporar os detalhes extraídos ao objeto business_data
                if details_data:
                    for key, value in details_data.items():
                        if value:  # Somente se o valor não for None/null
                            business_data[key] = value
                
                # Extrair coordenadas da URL
                try:
                    current_url = await page.url()
                    # Corrigido: Usar expressão regular para coordenadas
                    coords_match = re.search(r'@(-?\d+\.\d+),(-?\d+\.\d+)', current_url)
                    if coords_match:
                        lat, lng = coords_match.groups()
                        business_data["coordinates"] = {
                            "latitude": float(lat),
                            "longitude": float(lng)
                        }
                except Exception as e:
                    print(f"Erro ao extrair coordenadas: {str(e)}", file=sys.stderr)
                
                # Limpar o número de telefone (apenas dígitos)
                if business_data.get("phone"):
                    business_data["phone"] = re.sub(r'\D', '', business_data["phone"])
                
                # Voltar para a listagem de resultados pelo histórico de navegação
                try:
                    # Primeiro tentar com o botão de voltar
                    back_buttons = [
                        'button[aria-label="Back"]', 
                        'button[jsaction*="back"]', 
                        'button.VfPpkd-icon-LgbsSe[data-tooltip="Back"]',
                        'button[aria-label*="voltar"]'
                    ]
                    
                    back_clicked = False
                    for back_selector in back_buttons:
                        try:
                            back_button = await page.query_selector(back_selector)
                            if back_button:
                                await back_button.click()
                                back_clicked = True
                                # Tentativa de esperar pelo URL original
                                try:
                                    await page.wait_for_url(original_url, timeout=5000)
                                except Exception:
                                    pass  # Ignorar se o timeout ocorrer
                                break
                        except Exception:
                            continue
                    
                    # Se não conseguiu clicar no botão de voltar, usar histórico
                    if not back_clicked:
                        await page.goto(original_url, timeout=10000)
                    
                    # Aguardar um pouco após voltar
                    await asyncio.sleep(1)
                except Exception as e:
                    print(f"Erro ao voltar para a listagem: {str(e)} - tentando goto direto", file=sys.stderr)
                    # Último recurso
                    try:
                        await page.goto(original_url, timeout=10000)
                        await asyncio.sleep(1)
                    except Exception:
                        pass
            
            except Exception as e:
                print(f"Erro ao aguardar detalhes: {str(e)}", file=sys.stderr)
                # Tentar voltar à página original em caso de erro
                if original_url:  # Verificar se original_url foi definido
                    try:
                        await page.goto(original_url, timeout=10000)
                        await asyncio.sleep(1)
                    except Exception:
                        pass
            
        except Exception as e:
            print(f"Erro ao extrair detalhes completos: {str(e)}", file=sys.stderr)
            # Tentar recuperar a navegação
            if original_url:  # Verificar se original_url foi definido
                try:
                    await page.goto(original_url, timeout=10000)
                    await asyncio.sleep(1)
                except Exception:
                    pass
    
    # Filtrar campos vazios ou None
    return {k: v for k, v in business_data.items() if v is not None}

async def scroll_to_load_more(page: Page, max_scrolls: int = 10):
    """
    Rola a lista de resultados para carregar mais estabelecimentos
    
    Args:
        page: Objeto Page do Playwright
        max_scrolls: Número máximo de rolagens
    """
    try:
        # Identificar o contêiner de resultados que tem scroll
        scroll_containers = [
            'div[role="feed"]',
            'div.m6QErb[role="region"]',
            'div.m6QErb-qJTHM-haAclf'
        ]
        
        container_selector = None
        for selector in scroll_containers:
            container = await page.query_selector(selector)
            if container:
                container_selector = selector
                break
        
        if not container_selector:
            print("Não foi possível encontrar o contêiner de resultados para scroll", file=sys.stderr)
            return
        
        print(f"Realizando scroll para carregar mais resultados usando {container_selector}", file=sys.stderr)
        
        initial_count = await page.evaluate(f'''
            () => {{
                const container = document.querySelector('{container_selector}');
                return container ? container.querySelectorAll('a[href^="https://www.google.com/maps/place"]').length : 0;
            }}
        ''')
        
        print(f"Contagem inicial de elementos: {initial_count}", file=sys.stderr)
        
        for i in range(max_scrolls):
            # Rolar para baixo no contêiner
            await page.evaluate(f'''
                () => {{
                    const container = document.querySelector('{container_selector}');
                    if (container) {{
                        container.scrollTop = container.scrollHeight;
                        return true;
                    }}
                    return false;
                }}
            ''')
            
            # Aguardar um pouco para o carregamento
            await asyncio.sleep(2)
            
            # Verificar se mais elementos foram carregados
            new_count = await page.evaluate(f'''
                () => {{
                    const container = document.querySelector('{container_selector}');
                    return container ? container.querySelectorAll('a[href^="https://www.google.com/maps/place"]').length : 0;
                }}
            ''')
            
            # Se não carregou mais elementos, interromper
            if new_count <= initial_count and i > 0:
                print(f"Sem novos elementos após {i+1} rolagens. Parando.", file=sys.stderr)
                break
                
            print(f"Rolagem {i+1}: {new_count} elementos encontrados", file=sys.stderr)
            initial_count = new_count
            
            # Se o número é suficiente, podemos parar
            if new_count >= 30:  # Um número razoável para evitar muitas rolagens
                break
    
    except Exception as e:
        print(f"Erro durante o scroll: {str(e)}", file=sys.stderr)

async def scrape_google_maps(region: str, business_type: str, max_results: int = 10, keywords: str = None) -> List[Dict[str, Any]]:
    """
    Executa o scraping no Google Maps com base nos parâmetros fornecidos
    
    Args:
        region: Região de busca (bairro, cidade, CEP)
        business_type: Tipo de negócio (restaurantes, padarias, etc.)
        max_results: Número máximo de resultados a retornar
        keywords: Palavras-chave adicionais para a busca
        
    Returns:
        Lista de dicionários com os detalhes dos negócios encontrados
    """
    results = []
    
    print(f"Iniciando busca por '{business_type}' em '{region}'...", file=sys.stderr)
    
    # Inicializar o navegador
    async with async_playwright() as p:
        # Lançar o navegador em modo headless
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        await page.set_viewport_size({"width": 1366, "height": 768})
        
        # Construir a consulta
        search_query = f"{business_type} em {region}"
        if keywords:
            search_query += f" {keywords}"
        
        encoded_query = search_query.replace(" ", "+")
        url = f"https://www.google.com/maps/search/{encoded_query}"
        
        # Navegar para a URL com timeout ampliado
        print(f"Navegando para: {url}", file=sys.stderr)
        try:
            await page.goto(url, timeout=120000)
            
            # Aguardar elementos principais
            try:
                await page.wait_for_selector(
                    'div[role="feed"], a[href^="https://www.google.com/maps/place"], h1', 
                    timeout=30000
                )
                print("Elementos principais detectados", file=sys.stderr)
            except Exception as e:
                print(f"Aviso: Não conseguiu detectar elementos específicos: {str(e)}", file=sys.stderr)
                await asyncio.sleep(5)
                
            # Aguardar um tempo adicional para carregar dados dinâmicos
            await asyncio.sleep(3)
            
        except Exception as e:
            print(f"Erro ao navegar para a página: {str(e)}", file=sys.stderr)
            await browser.close()
            return results
        
        # Realizar scroll para carregar mais resultados
        await scroll_to_load_more(page, max_scrolls=10)
        
        # Extrair os estabelecimentos
        print("\nExtraindo dados dos estabelecimentos...", file=sys.stderr)
        
        try:
            # Identificar os elementos de negócios
            business_elements = await page.query_selector_all('a.hfpxzc[aria-label]')
            print(f"Encontrados {len(business_elements)} elementos de negócios com aria-label", file=sys.stderr)
            
            # Se não encontrou elementos com a classe específica, tente sem a classe
            if not business_elements or len(business_elements) == 0:
                business_elements = await page.query_selector_all('a[href^="https://www.google.com/maps/place"][aria-label]')
                print(f"Encontrados {len(business_elements)} elementos de negócios com aria-label (busca alternativa)", file=sys.stderr)
            
            # Se ainda não encontrou, tente outro seletor
            if not business_elements or len(business_elements) == 0:
                business_elements = await page.query_selector_all('a[href^="https://www.google.com/maps/place"]')
                print(f"Encontrados {len(business_elements)} elementos pelo seletor de links", file=sys.stderr)
            
            # Extrair detalhes de cada negócio
            count = 0
            
            for element in business_elements:
                if count >= max_results:
                    break
                
                try:
                    # Extrair os detalhes completos
                    business_data = await extract_business_details(page, element, max_details=True)
                    print(f"Dados extraídos: {business_data}", file=sys.stderr)  # Log detalhado

                    # Adicionar apenas se tiver ao menos o nome
                    if business_data and business_data.get("name"):
                        results.append(business_data)
                        print(f"Extraído: {business_data.get('name')}", file=sys.stderr)
                        count += 1
                except Exception as e:
                    print(f"Erro ao processar elemento: {str(e)}", file=sys.stderr)
            
            print(f"\nTotal de {len(results)} estabelecimentos extraídos.", file=sys.stderr)
            
        except Exception as e:
            print(f"Erro durante a extração: {str(e)}", file=sys.stderr)
        
        # Fechar o navegador
        await browser.close()
        
    return results

async def main():
    """
    Função principal que lê parâmetros da entrada padrão e executa o scraping
    """
    try:
        # Ler parâmetros da entrada padrão (STDIN)
        input_data = json.loads(sys.stdin.read())
        
        # Extrair parâmetros
        region = input_data.get("region", "")
        business_type = input_data.get("business_type", "")
        max_results = int(input_data.get("max_results", 10))
        keywords = input_data.get("keywords", "")
        
        # Validar parâmetros obrigatórios
        if not region or not business_type:
            error_msg = {
                "error": "Parâmetros insuficientes",
                "message": "É necessário fornecer ao menos região e tipo de negócio"
            }
            print(json.dumps(error_msg))
            sys.exit(1)
        
        # Executar o scraping
        results = await scrape_google_maps(
            region=region,
            business_type=business_type,
            max_results=max_results,
            keywords=keywords
        )
        
        # Retornar resultados como JSON para o STDOUT
        print(json.dumps(results, ensure_ascii=False))
        
    except json.JSONDecodeError:
        error_msg = {
            "error": "Formato inválido",
            "message": "Os parâmetros devem ser fornecidos em formato JSON"
        }
        print(json.dumps(error_msg))
        sys.exit(1)
    except Exception as e:
        error_msg = {
            "error": "Erro durante a execução",
            "message": str(e)
        }
        print(json.dumps(error_msg))
        sys.exit(1)

if __name__ == "__main__":
    # Configurar timeout maior para o asyncio
    asyncio.run(main())